I"I/<h1 id="overview">Overview:</h1>

<p>It is trivial to construct the fractal-like attractor for an iterated function system, since each IFS defines a unique fractal. However the inverse of this problem is difficult in general; given an an attractor (in this case an image), what is the iterated function system that generates that attractor? This project constructs an IFS which approximates a provided image. The non-trivial part of this project was to construct a dataset for training a model. Using graph-directed constructions of fractals, a dataset of images with uniformly distributed fractal dimension was constructed.</p>

<h1 id="results">Results:</h1>

<p>Using a graph-directed construction of iterated function systems, we can define the IFS for a large class of fractals. Essentially, we can encode the IFS for a fractal using an adjacency matrix. From an adjacency matrix, we can construct an image. The dataset consists of matrices E0 and images which are generated by E0. A keras model was then trained to predict E0 from the image generated by E0, so that from arbitrary images we can retrieve the IFS which best approximates the provided image.</p>

<h1 id="code-walkthrough">Code Walkthrough</h1>

<p>import pickle
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.pylab import rcParams
from PIL import Image
from progress_bar import progressbar
from scipy import optimize
from scipy.stats import gumbel_l
from statistics import mean
import pickle
import pandas as pd</p>

<p>class make_base9_im():
    ‘’’
    This class converts E0 matrices into an image representing the IFS generated
    by E0 using the standard base 9 stuff.
    ‘’’
    e0 = []
    size = 700
    res = 3</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_x0(e0):
    x0 = []
    for i in range(9):
        for j in range(9):
            if e0[i][j] == 1:
                x0.append(str(i)+str(j))
    return x0   

def get_xn(x0, str_length):
    xn = x0 #initialize Xn
    for loops in range(str_length):
        xnplus1 = []
        for x in xn:
            last = x[-1]
            for y in x0:
                if y[0] == last:
                    xnplus1.append(x+y[-1])    
        xn = xnplus1       
    return xn

def rgb_to_gray(rgb): 
    rgb = np.asarray(rgb)
    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.float64)

def get_points(xn):
    points = []
    for route in xn:
        scale = 2/3
        pos = np.array([0.0, 0.0])
        for j in route:
            dpos = np.empty([0])
            if j == '0':
                dpos = np.array([-1, -1])
            if j == '1':
                dpos = np.array([0, -1])
            if j == '2':
                dpos = np.array([1, -1])
            if j == '3':
                dpos = np.array([-1, 0])
            if j == '4':
                dpos = np.array([0, 0])
            if j == '5':
                dpos = np.array([1, 0])
            if j == '6':
                dpos = np.array([-1, 1])
            if j == '7':
                dpos = np.array([0, 1])
            if j == '8':
                dpos = np.array([1, 1]) 
            dpos = dpos.astype('float64')
            pos += scale*dpos
            scale *= 1/3
        points.append((pos + [1, -1])/2) 
    return np.asarray(points)

def get_im(e0, size, res):
    xn = make_base9_im.get_xn(make_base9_im.get_x0(e0), res)
    points = make_base9_im.get_points(xn) * (size-1)
    im = Image.new("RGB", (size, size), "#FFFFFF")
    pixels = im.load()
    
    for point in points:
        pixels[round(abs(point[0])), round(abs(point[1]))] = (0, 0, 0)
        
    return make_base9_im.rgb_to_gray(im)

def rescale_im(image, size):
    if type(image) == np.ndarray:
        img_data = image
        converted_im = Image.fromarray(img_data).convert("L")
        img_data = np.asarray(converted_im.resize((size, size), Image.ADAPTIVE)) #resizing
        return img_data
</code></pre></div></div>

<p>class make_base4_im():
    ‘’’
    This class converts E0 matrices into an image representing the IFS generated
    by E0 using the standard base 4 stuff.
    ‘’’
    e0 = []
    size = 700
    res = 3</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_x0(e0):
    x0 = []
    for i in range(4):
        for j in range(4):
            if e0[i][j] == 1:
                x0.append(str(i)+str(j))
    return x0   

def get_xn(x0, str_length):
    xn = x0 #initialize Xn
    for loops in range(str_length):
        xnplus1 = []
        for x in xn:
            last = x[-1]
            for y in x0:
                if y[0] == last:
                    xnplus1.append(x+y[-1])    
        xn = xnplus1       
    return xn

def rgb_to_gray(rgb): 
    rgb = np.asarray(rgb)
    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140]).astype(np.float64)

def get_points(xn):
    points = []
    for route in xn:
        scale = 1/2
        pos = np.array([0.0, 0.0])
        for j in route:
            dpos = np.empty([0])
            if j == '0':
                dpos = np.array([-1, -1])
            if j == '1':
                dpos = np.array([1, -1])
            if j == '2':
                dpos = np.array([1, 1])
            if j == '3':
                dpos = np.array([-1, 1])
 
            dpos = dpos.astype('float64')
            pos += scale*dpos
            scale *= 1/2
        points.append((pos + [1, -1])/2) 
    return np.asarray(points)

def get_im(e0, size, res):
    xn = make_base4_im.get_xn(make_base4_im.get_x0(e0), res)
    points = make_base4_im.get_points(xn) * (size-1)
    im = Image.new("RGB", (size, size), "#FFFFFF")
    pixels = im.load()
    
    for point in points:
        pixels[round(abs(point[0])), round(abs(point[1]))] = (0, 0, 0)
        
    return make_base4_im.rgb_to_gray(im)

def rescale_im(image, size):
    if type(image) == np.ndarray:
        img_data = image
        converted_im = Image.fromarray(img_data).convert("L")
        img_data = np.asarray(converted_im.resize((size, size), Image.ADAPTIVE)) #resizing
        return img_data
</code></pre></div></div>

<p>```</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>We don't know the distribution of the dimensions for all fractals in nature, so we create
a data set that has an approximately uniform distribution of dimension. 

The goal here is to create a function that produces a list of E0 matrices, where the distribution
of the dimensions of all such E0 matrices is uniform. In this way we can create a data set that is
less biased towards any particular dimension (there are caveats with this). 

To create an E0 matrix, we create a random matrix [ceil(a_{i,j} - (1-p)]_{i,j &lt;= base} with a 
being a uniformly distributed random number in [0, 1]. The value p is constant, and controls how many
1's and 0's there are in E0. There isn't just one correct value to pick for p, since for
fixing p at some value gives a narrow distribution of dimensions for the IFS generated by E0. 
So the trick is to find a relationship between p and the dimension of E0 so that we can 
vary p to create a uniformly distributed (in dimension) training set.

When p = 1, then E0 will contain only 1's, and when p = 0, then E0 will contain only 0's

First we compute the relationship between p and the dimension of the IFS generated by E0, 
then we use the inverse of that relationship to create a set of E0 such that the dimensions 
of all E0 in the set are uniformly distributed.
</code></pre></div></div>

<p>```python
def make_e0(base, n_dbins = 20, l = 80):</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def dim_root_estimate(A):
    """
    Takes a square matrix, and returns the dimension of the IFS generated by A
    
    Finds the root of the the function f(x) = spec_rad(A*(1/r)^d) - 1
    """
    def spec_rad(A):
        return max(np.abs(np.linalg.eigvals(A)))

    def dimension_root(d, A): #returns 0 when d is the dimension for A
        """
        Recalling that the dim of the IFS generated by A is the value d such 
        that spec_rad(A*(1/r)^d) = 1 (where r is the canonical scaling factor)
        """
        return 1 - spec_rad(A * np.power(1/np.sqrt(np.sqrt(A.size)), d))
    
    estimate = 1
    try:
        return optimize.newton(dimension_root, x0 = estimate, args = (A, ))
    except:
        return -1
    
def get_dim_func(base, num_samples = 100):
    """
    Returns a function that converts dimensions into probabilities. 
    
    First we fit probabilities to dimension, then we return the inverse
    of the fitted function
    """
    def generalized_exp(x, a, b):
        return np.log(a*x + b)

    def get_gumbel_l_distr(p):
        """
        Get's the gumbel distribution parameters for a given p. 
        """
        fit_vals = []
        
        for i in range(num_samples):
            A = np.abs(np.ceil(np.random.rand(base, base) - (1-p)))
            if np.max(A) != 0:
                fit_vals.append(dim_root_estimate(A))
        params = gumbel_l.fit(fit_vals)
        return params
           
    
    print("\n****************** Grabbing Exp. Params ******************\n")
    print("Creating Data to Fit...")
    progress = progressbar(total = num_samples, 
                           fmt = progressbar.FULL)
    
    probs = np.linspace(0.1, 1, num_samples)
    fit_data = []

    for p in probs:
        progress.current +=1 
        progress.__call__()
        
        try:
            temp_avg_dim = get_gumbel_l_distr(p)[0]
            fit_data.append([p, temp_avg_dim])
        except:
            pass
    
    fit_data = np.asarray(fit_data)
    
    print("\nFitting generalized_exp(p)...", end = '')
    expp = optimize.curve_fit(generalized_exp, fit_data[:, 0], fit_data[:, 1])  
    print("Done...")
    plt.xlabel('Probability $p$')
    plt.ylabel("Dimension")
    plt.title("Fitted Curve vs Target Values")
    plt.scatter(fit_data[:, 0], 
                [generalized_exp(p, expp[0][0], expp[0][1])for p in fit_data[:, 0]], 
                label = 'generalized_exp fit')
    plt.scatter(fit_data[:, 0], 
                fit_data[:, 1], label = 'target vals')
    plt.legend(loc = 'best')
    plt.show()
    print("Params: {}".format(expp[0]))
    
    def dim_func(x, a = expp[0][0], b = expp[0][1]):
        """
        The algebraic inverse of generalize_exp, with parameters tuned by the
        code above
        """
        if np.abs(x) &lt; 2:
            return (np.exp(x)-b)/a
        else:
            return None
        
    return dim_func

dim_func = get_dim_func(base = base)

print("\n****************** Making Encoding Matrices ******************\n")

def trunc(x, digits = 3):
    if type(x) == float:
        return round(x, digits)
    return None

def bins(n):
    dx = 2/n
    return [[i*dx, (i+1)*dx] for i in range(n)]

set_of_bins = bins(n_dbins)
set_of_p = [dim_func(bk[0] + 1/n_dbins) for bk in set_of_bins]
bins_of_E = [[] for i in range(n_dbins)]
set_of_dims = []
i=2 #skip the first bin because it's just all zeroes

print("Filling bins...")
while i &lt; len(set_of_bins):
    bk = set_of_bins[i]
    p = 1-set_of_p[i]
    E = abs(np.ceil(np.random.rand(base, base) - p))
    dim = dim_root_estimate(E)
    
    if dim &gt;= bk[0] and dim &lt;= bk[1]:
        bins_of_E[i].append(E)
        set_of_dims.append(dim)
    
    if len(bins_of_E[i]) &gt;= l:
        i += 1
        print("Bin {} out of {}: [{}, {}]".format(i, 
                                                  n_dbins, 
                                                  trunc(bk[0]), 
                                                  trunc(bk[1])))
        
plt.hist(set_of_dims, bins = 100)
plt.xlabel("Dimension")
plt.ylabel("Count")
plt.title("Distribution of Dimensions in the Data Set")
plt.show()

set_of_E = [E for sublist in bins_of_E for E in sublist] 

print("Done!")

return set_of_E
</code></pre></div></div>
:ET