---
layout: post
title: "Modern NLP on Financial Earnings Reports "
subtitle: "A data-model pipeline which demonstrates partial correlation between the linguistic content of earnings reports and long term performance."
date: 2022-04-03 19:00:00 -0400
background: '/img/posts/10_topics_1259samples.png'
---

# Overview:

Using assorted webscraping technologies, I pulled thousands of relevant financial earnings reports from various sources. The timestamps and relevant ticker information for these time stamps were populated inside a custom-made SQL database on GCP. These documnents were treated as an investible universe from which names of stocks of interest could be found. Using an ensemble of language models and clustering algorithms, I created a pipeline through which one could query the correlation of any desired metric against the linguistic content of the large database of text. 

# Primary Results:

The model was used to identify stocks of interest from a large investible universe on the order of 5k tickers. The model offloaded the need for the traditional manual thinning of the investible universe, allowing for more efficient searching of potential portfolio candidates. The model was comprised of a LDA/XGB component which clustered documents in an unsupervised fashion, and a BERT-type head for predicting on these clusters.  

# Code Walkthrough:

Below is only the "head" of the pipeline, where new transcript data is predicted upon. The full ensemble and library is unavailable for public eyes at this time, but if there is interest just email me! 


```python
import sys
sys.path.append('/home/oliver/Documents/data_pipeline/')
import sg #custom library
import pandas as pd
import numpy as np

sys.path.append("/home/oliver/Documents/data_pipeline/nlp/")
from transcript_parser import transcript_parser
from transcript_ensemble_model import LDA_Model, XGB_Classifier_from_LDA
from xgboost import plot_importance

def make_predictions(new_data_dir,
                     new_data_name,
                     num_passes,
                     output_filename = 'most_interesting.csv',
                     disp = False,
                     use_best = False):
    """
    This script parses through a directory (folder) full of sentieo smart transcripts, and then runs a series
    of models on the set of smart transcripts. A consensus is taken at the end, giving the transcripts
    that are most likely interesting and saving this result to a file.
    """


# =============================================================================
#     #give the location of the transcripts we want to test
#     new_data_dir = "/home/oliver/Documents/data_pipeline/nlp/vj_transcripts/"
#
#     #give the name of the file of the new data
#     #This will be the name of the data parsed from the above directory
#     new_data_name = 'vj_transcript_data.pkl'
#
#     #How many different models do you want? More accurate results will come with a
#     #higher number of passes, compute time is LINEAR with the number of passes (not exponential)
#     num_passes = 10
#
#     #give the desired name of the output file:
#     output_filename = "most_interesting.csv"
# =============================================================================

    #where are all the files we care about, the current working directory.
    #should be the locationf all the '...transcript_data.pkl' files
    current_working_dir = "/home/oliver/Documents/data_pipeline/nlp/"

    #create an instance of the transcript parser class, to be used to parse through
    #the new transcript data in the new_data_dir
    tp = transcript_parser(new_data_dir)

    try:
        #try and read the unseen data, fails when file not found
        unseen_transcript_data = pd.read_pickle(current_working_dir + new_data_name)
        del unseen_transcript_data['document_text']
        del unseen_transcript_data['document_length']
    except:
        #if the file hasn't been found, we use the transcript parser to create the formatted
        #transcript data to be used in the model, and we then save the transcript data for
        #future runs
        tp.pdf_dir_attr = tp.pdf_dir_attr.reset_index(drop = True).iloc[:, :]
        unseen_transcript_data = tp.prepare_data_for_model()
        pd.to_pickle(unseen_transcript_data, current_working_dir + new_data_name)


    """
    Initialize prediction df, the temporary location of the predictions on the new topics
    """
    unseen_transcript_data['int_prediction'] = [0 for x in unseen_transcript_data['ticker']]

    """
    Get the labeled data that we will use to train the models
    This is the formatted training data, and should not need to be updated or changed!
    """
    labeled_transcript_data = pd.read_pickle(current_working_dir + "lda_transcript_data_clrd.pkl")

    for i in range(num_passes):
        print("\n********************** pass number {}/{} **********************".format(i + 1, num_passes))

        """
        Initialize the new LDA model using some parameters
        """
        lda = LDA_Model(labeled_transcript_data)
        lda.num_topics = np.random.randint(10, 25)
        print("Number of LDA topics = {}".format(lda.num_topics))

        if use_best:
            lda.use_current_best_lda_xgb_clrd_model(lda.num_topics)

        if not(use_best):
            alpha = 50/lda.num_topics
            eta = 'auto'
            lda.fitness_function([alpha, eta], disp=False)

        if disp:
            lda.plot_tsne(perplexity=35, two_colors=True)

        #predict on the unseen data, adding a column of topic prediction vectors
        unseen_transcript_data = lda.predict_on_unseen_data(unseen_transcript_data)

        """
        Initialize the XGB Classifier, and provide the updated lda.transcript_data
        """
        #train the xgb classifier on the lda's data
        xgb = XGB_Classifier_from_LDA(lda.transcript_data)
        xgb.train_model(disp = False) #I have never wanted to see it disp

        #print out the numbers we care about
        print("acc_on_oos_int: {}".format(sg.truncate(xgb.acc_on_oos_int)))
        print("acc_on_val_all: {}".format(sg.truncate(xgb.acc_on_val_all)))
        print("perc_int: {}".format(sg.truncate(xgb.perc_int)))

        #update the preductions
        new_predictions = [xgb.xgb_model.predict(x.reshape(1, -1))[0]
                           for x in unseen_transcript_data['topic_predictions']]
        unseen_transcript_data['int_prediction'] = np.array(unseen_transcript_data['int_prediction']) + new_predictions

        #ranks the most important topic for each run, ranked by information gain
        xgb_importance = xgb.get_importance()
        #print(xgb_importance.head(3))

        #plot the most important topics and their word distributions
        if disp:
            plot_importance(xgb.xgb_model)

            lda.plot_topic_dist(list(xgb_importance.loc[:2,'feature_number']),
                                num_words_per_topic= 10,
                                width = 0.2)

            lda.plot_topic_word_cloud(list(xgb_importance.loc[:3,'feature_number']), num_words = 50)


        #If the accuracy is good for this model, we save and update the last one on file:
        if lda.better_than_current_best_lda_xgb_model(lda.num_topics,
                                                      xgb.acc_on_oos_int):
            model_name = "{}_best_clrd_".format(lda.num_topics)
            print("\nFound a better model! Updating accordingly...")
            lda.update_lda_xgb_model_lookup(model_name,
                                            xgb.acc_on_oos_int,
                                            lda.num_topics)

    #takes the consensus of the model predictions
    max_prediction_count = np.max(unseen_transcript_data['int_prediction'])
    #'normalize' the int_predictions
    unseen_transcript_data['int_prediction'] = unseen_transcript_data['int_prediction']/max_prediction_count
    most_interesting = unseen_transcript_data[unseen_transcript_data['int_prediction'] > 0]
    most_interesting = most_interesting[['ticker','date', 'int_prediction']].sort_values(by = ['int_prediction', 'ticker'],
                                                                                         ascending = False)

    #print the most interesting documents
    print("\n********************** Most Intersting Documents **********************".format(i + 1, num_passes))
    print(most_interesting[['ticker', 'date', 'int_prediction']])

    #save the most interesting document list
    most_interesting.to_csv(output_filename, index = False)
    return most_interesting


#give the location of the transcripts we want to test
new_data_dir = "/home/oliver/Documents/data_pipeline/nlp/vj_transcripts/"

#give the name of the file of the new data
#This will be the name of the data parsed from the above directory
new_data_name = 'vj_transcript_data.pkl'

#How many different models do you want? More accurate results will come with a
#higher number of passes, compute time is LINEAR with the number of passes (not exponential)
num_passes = 1

#give the desired name of the output file:
output_filename = "most_interesting.csv"

most_interesting = make_predictions(new_data_dir,
                                    new_data_name,
                                    num_passes,
                                    output_filename)
```

